In this section we evaluate \ICDCN{} against three other implementations of a concurrent BST, namely those based on:
%%
\begin{enumerate}[label=(\roman*)]
\item the lock-free internal BST by Howley and Jones~\cite{HowJon:2012:SPAA}, denoted by \HJBST{},
\item the lock-free external BST by Natarajan and Mittal~\cite{NatMit:2014:PPoPP}, denoted by \NMBST{}, and 
\item the RCU-based internal BST by Arbel and Attiya~\cite{ArbAtt:2014:PODC}, denoted by \CITRUS{}.
\end{enumerate}

\input{c06/icdcn/experiments-graphs-stampede-keySweep}
\input{c06/icdcn/experiments-graphs-stampede-threadSweep}

The results of our experiments are shown in \figref{icdcn-keySweep} and \figref{icdcn-threadSweep}. In \figref{icdcn-keySweep}, each row represents a specific workload (read-dominated, mixed or write-dominated) and each column represents a specific key space size; \textit{small} (8Ki to 64Ki), \textit{medium} (128Ki to 1Mi) and \textit{large} (2Mi to 16Mi). \figref{icdcn-threadSweep} shows the scaling with respect to the number of threads for key space size of 2\textsuperscript{19} (512Ki). We do not show the numbers for \CITRUS{} in the graphs as it had the worst performance among all implementations (slower by a factor of four in some cases). This is not surprising as \CITRUS{} is optimized for read operations (\emph{e.g.}, 98\% reads \& 2\% updates)~\cite{ArbAtt:2014:PODC}.


As the graphs show, \ICDCN{} achieved nearly same or higher throughput than the other two implementations for medium and large key space sizes (except for medium key space size with write-dominated workload). Specifically, at 32 threads and for a read-dominated workload, \ICDCN{} had 35\% and 24\% higher throughput than the next best performer for key space sizes of 512Ki and 1Mi, respectively. Also, at 32 threads and for a mixed workload, \ICDCN{} had 27\% and 19\% higher throughput than the next best performer for key space sizes of 1Mi and 2Mi, respectively. Overall, \ICDCN{} outperformed the next best implementation by as much as 35\%; it outperformed \HJBST{} by as much as 44\% and \NMBST{} by as much as 35\% (both achieved for medium key space sizes). For large key space sizes, the overhead of traversing the tree appears to dominate the overhead of actually modifying the operation's window, and the gap between various implementations becomes smaller.

\input{Figures/icdcn/comparison}
There are several reasons why \ICDCN{} outperformed the other two implementations in many cases. First, as \tabref{icdcn-comparison} shows, our algorithm allocates fewer objects than the two other algorithms on average considering the fact that the fraction of insert operations will generally be larger than the fraction of delete operations in any realistic workload. Further, we observed in our experiments that the number of simple delete operations outnumbered the number of complex delete operations by two to one, and our algorithm does not allocate any object for a simple delete operation. Second, again as \tabref{icdcn-comparison} shows, our algorithm executes the same number of atomic instructions as in~\cite{NatMit:2014:PPoPP} for insert operations;  and, in all the cases,  executes same or fewer atomic instructions than in~\cite{HowJon:2012:SPAA}. This is important since an atomic instruction is more expensive to execute than a simple read or write instruction. Third, we observed in our experiments that \ICDCN{} had a smaller memory footprint than the other two implementations (by almost a factor of two) since it uses internal representation and allocates fewer objects. As a result, it was likely able to benefit from caching to a larger degree than \HJBST{} and \NMBST{}.