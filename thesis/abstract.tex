Over the last decade processor clock speeds have hit a wall. But the demand for performance improvements continues to grow. So there has been a major shift towards multi-core and many-core processors. However, most of the software applications running on multi-core processors do not fully utilize all the cores. Rewriting the entire software stack for large applications seems impractical. On the other hand, improving the performance of common data structures which are the building blocks of any software application seemed feasible. This motivated the design of concurrent data structures. 

Designing a concurrent data structure is far more challenging than its sequential counterpart because threads executing concurrently may interleave in exponential possible ways. A concurrent data structure should preserve its equivalent sequential specifications for all such interleavings.

In this work, we focus on concurrent binary search trees. We present a blocking and a non-blocking algorithm for concurrent manipulation of a binary search tree in an asynchronous shared memory system that supports search, insert and delete operations. We also provide a general technique to optimize them. Our technique is sufficiently general in the sense that it can be applied to a variety of concurrent binary search trees based on both blocking and non-blocking approaches.

Moreover, we also present several techniques to make search operations on such binary search trees \emph{wait-free}. Our techniques have the advantage that a search operation does not need to perform any write instruction on shared memory thereby minimizing the cache traffic. 

Experiments indicate that our algorithms perform best in most cases. And our optimization technique improves performance of our algorithms and other existing algorithms. 