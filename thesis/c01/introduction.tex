With the growing prevalence of multi-core, multi-processor systems, concurrent data structures are becoming increasingly important. In such a data structure, multiple processes may need to operate on the data structure at the same time. Contention between different processes must be managed in such a way that all operations complete correctly and leave the data structure in a valid state.

Concurrency is often managed using locks. A lock can be used to achieve mutual exclusion, which can then be used to ensure that any updates to the data structure or a portion of it are performed by one process at a time. This makes it easier to design a lock-based concurrent data structure and reason about its correctness. Moreover, this also makes it easier to implement a lock-based data structure and debug it than its lock-free counterpart. Lock-based algorithms for concurrent versions of many important data structures for storing and managing shared data have been developed including linked lists, queues, priority queues, hash tables and skiplists (\emph{e.g.}, \cite{MicSco:1996:PODC, Mic:2002:SPAA,Lea:2003:JSR166,HelHer+:2005:OPODIS,LevHer+:2007:SIROCCO, HerSha:2012:Book}).

However, locks are blocking; while a process is holding a lock, no other process can access the portion of the data structure protected by the lock. If a process stalls while it is holding a lock, then the lock may not be released for a long time. This may cause other processes to wait on the stalled process for extended periods of time. As a result, lock-based implementations of concurrent data structures are vulnerable to problems such as deadlock, priority inversion and convoying~\cite{HerSha:2012:Book}.

Non-blocking algorithms avoid the pitfalls of locks by using special (hardware-supported) \emph{read-modify-write} instructions such as \emph{load-link/store-conditional (\LL{}/\SC{})}  and \linebreak \emph{compare-and-swap (\CAS{})}~\cite{HerSha:2012:Book}. Non-blocking implementations of many common data structures such as queues, stacks, linked lists, hash tables and search trees  have been proposed (\emph{e.g.}, \cite{Mic:2002:SPAA,FomRup:2004:PODC,BenFin+:2005:SPAA,EllFat+:2010:PODC,HerSha:2012:Book,BraPet:2012:SPAA,HowJon:2012:SPAA,NatMit:2013:DISC,NatSav+:2013:SSS,NatMit:2014:PPoPP,DraVec+:2014:PPoPP,EllFat+:2014:PODC}).

Binary search tree is one of the fundamental data structures for organizing \emph{ordered} data that supports search, insert and delete operations~\cite{CorLei+:1991:MIT}. A binary search tree may be unbalanced (different leaf nodes may be at very different depths) or balanced (all leaf nodes are at roughly the same depth). A balanced binary search tree provides better worst-case guarantees about the cost of performing an operation on the tree. However, in many cases, the overhead of keeping the tree balanced, especially in a concurrent environment, may incur significant overhead. As a result, in many cases, an unbalanced binary search tree  outperforms a balanced binary search tree in practice. In this work, our focus is on developing efficient concurrent algorithms for an \emph{unbalanced} binary search tree. 

Concurrent algorithms for unbalanced binary search trees have been proposed in~\cite{EllFat+:2010:PODC,HowJon:2012:SPAA,NatMit:2014:PPoPP,DraVec+:2014:PPoPP,EllFat+:2014:PODC,ChaDan+:2014:PODC,ArbAtt:2014:PODC}. Algorithms in~\cite{DraVec+:2014:PPoPP,ArbAtt:2014:PODC} are blocking (or lock-based), whereas those in~\cite{EllFat+:2010:PODC,HowJon:2012:SPAA,NatMit:2014:PPoPP,EllFat+:2014:PODC,ChaDan+:2014:PODC} are non-blocking (or lock-free). Also, algorithms in~\cite{HowJon:2012:SPAA,DraVec+:2014:PPoPP,ArbAtt:2014:PODC,ChaDan+:2014:PODC} use internal representation of a search tree in which all nodes store data, where as those in~\cite{EllFat+:2010:PODC,NatMit:2014:PPoPP,EllFat+:2014:PODC} use an external representation of  a search tree in which only leaf nodes store data (data stored in internal nodes is used for routing purposes only).

Algorithms that use internal representation of a search tree have to address the problem that arises due to a key moving from one location in the tree to another. This occurs when the key undergoing deletion resides in a binary node, which requires it to be either replaced with its predecessor (next smallest key) or its successor (next largest key). As a result, an operation traversing the tree may fail to find the target key both at its old location and at its new location, even though the target key was continuously present in the tree. Different algorithms use different approaches to handle the problem arising due to key movement. The algorithm by Drachsler \emph{et al.} in~\cite{DraVec+:2014:PPoPP} maintains a \emph{sorted} linked list of all the keys in the tree. If the traversal of the tree fails to find a given key, then an operation traverses the linked list to look for the key. The algorithm by Arbel and Hattiya~\cite{ArbAtt:2014:PODC} uses the RCU (Read-Copy-Update) framework (first employed in Linux kernels) to allow reads to occur concurrently with updates.

Most of the concurrent algorithms (for BSTs) that have proposed so far use a na{\"i}ve approach and simply restart the traversal from the root of the tree~\cite{EllFat+:2010:PODC,HowJon:2012:SPAA,NatMit:2014:PPoPP,DraVec+:2014:PPoPP,ArbAtt:2014:PODC}. This is especially undesirable if the tree has large height, and the overhead of repeatedly traversing the tree may dominate all other overheads of performing an operation.

Recently, a few algorithms have been proposed in which an operation attempts to recover from a failure \emph{locally}~\cite{EllFat+:2014:PODC,ChaDan+:2014:PODC}. The algorithm in~\cite{EllFat+:2014:PODC}, which is based on external representation and builds upon the algorithm in~\cite{EllFat+:2010:PODC}, maintains a stack of the nodes visited during the traversal of the tree and simply restarts from the last ``unmarked'' node  (a node is marked before it is removed from the tree). Intuitively, this works because, in an external search tree, keys \emph{do not} move from one location in the tree to another. However, in a search tree based on internal representation, keys may move from one location (in the tree) to another. This occurs when the key undergoing deletion resides in a binary node, which requires it to be either replaced with its predecessor (next smallest key) or its successor (next largest key). This causes two problems. First, an operation traversing the tree may fail to find the target key both at its old location and at its new location, even though the target key was continuously present in the tree. Second, it is not always safe to simply restart from the last unmarked node in the stack since the key may have moved to an ancestor of such a node. Their restart approach is, however, sufficiently general that it can be applied to other concurrent search trees based on external representation~\cite{NatMit:2014:PPoPP}.

The algorithm in~\cite{ChaDan+:2014:PODC},  which is based on internal representation, uses \emph{backlink pointers} to find its way and recover from a failure while executing an operation. Their restart approach appears to be customized for their concurrent search tree and is not clear how it can be extended to other concurrent search trees based on internal representation.

\section{Contributions}
First we present a new \emph{lock-based} algorithm for concurrent manipulation of a binary search tree in an asynchronous shared memory system that supports search, insert and delete operations. Our algorithm is based on an internal representation of a search tree as in~\cite{DraVec+:2014:PPoPP,ArbAtt:2014:PODC}. However, as in~\cite{NatMit:2014:PPoPP}, it operates at edge-level (locks edges) rather than at node-level (locks nodes); this minimizes the contention window of a write operation and improves the system throughput. 
%%
Further, in our algorithm, 
%%
\begin{enumerate*}[label=(\roman*)]
\item a search operation uses only read and write instructions, 
\item an insert operation does not acquire any locks, and
\item a delete operation only needs to lock up to four edges in the absence of contention.
\end{enumerate*}
%%
Our experiments indicate that our lock-based algorithm outperforms existing algorithms for a concurrent binary search 
tree---blocking as well as non-blocking---for medium-sized and larger trees, achieving up to \castleMaximumgap{} higher throughput than the next best algorithm.

Second we extend the previous algorithm to develop a new \emph{lock-free} algorithm. It combines ideas from two existing lock-free algorithms, namely those by Howley and Jones~\cite{HowJon:2012:SPAA} and Natarajan and Mittal~\cite{NatMit:2014:PPoPP}, and is especially \emph{optimized for the conflict-free scenario}. Like Howley and Jones' algorithm, it uses internal representation of a search tree in which all nodes store keys. Also, like Natarajan and Mittal's algorithm, it operates at edge-level rather than node-level and does not use a separate explicit object for enabling coordination among conflicting operations. As a result, it inherits benefits of both the lock-free algorithms. Specifically, when compared to modify operations of Howley and Jones' internal binary search tree, its modify operations 
\begin{enumerate*}[label=(\alph*)]
\item have a smaller contention window, 
\item allocate fewer objects, 
\item execute fewer atomic instructions, and 
\item have a smaller memory footprint. 
\end{enumerate*}
%%
Our experiments indicate that our new lock-free algorithm outperforms other lock-free algorithms in most cases, providing up to \icdcnMaximumgap{} improvement in some cases over the next best algorithm.

Third, we present a general approach for local recovery that enables a process to quickly recover from a failure while performing an operation by restarting the traversal from a point ``close'' to the operation's window rather than the root of the tree.  Our approach can be applied to many existing concurrent algorithms for maintaining binary search trees using internal representation---blocking as well as non-blocking---such as those in~\cite{HowJon:2012:SPAA,DraVec+:2014:PPoPP,ArbAtt:2014:PODC,RamMit:2015:PPoPP}. Our local recovery approach uses only local variables and does not require modifying a tree node (of the original algorithm) to store any additional information. Using experimental evaluation, we demonstrate that our local recovery approach can yield significant speed-ups for many concurrent algorithms.

Finally, we present two light-weight techniques to make search operations for concurrent binary search trees based on internal representation, such as those in those in~\cite{HowJon:2012:SPAA,DraVec+:2014:PPoPP,ArbAtt:2014:PODC,RamMit:2015:ICDCN,RamMit:2015:PPoPP}, \emph{wait-free} with low additional overhead. Both of our techniques have the desirable feature that a search operation does not need to perform any write instructions on the share memory thereby minimizing the cache coherence traffic.

\section{Dissertation Roadmap} 
This dissertation organized as follows. We first describe the key concepts and techniques related to concurrent data structures in \chapterref{\preliminaries}. Then we describe our lock-based algorithm for a binary search tree in \chapterref{castle} followed by our lock-free algorithm in \chapterref{icdcn}. Our general technique for local recovery is described in \chapterref{localRecovery}. Then we discuss \emph{wait-free} techniques for search operations in \chapterref{waitFreeSearch}. The experimental evaluation of different concurrent algorithms for a binary search tree is described in \chapterref{experiments}. Finally \chapterref{conclusion} concludes the dissertation and outlines directions for future research.